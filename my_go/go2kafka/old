package main

import (
	"fmt"
	"os"
	"strings"
	"time"

	"github.com/Shopify/sarama"
	cluster "github.com/bsm/sarama-cluster" //support automatic consumer-group rebalancing and offset tracking
	"github.com/op/go-logging"
)

var logger = logging.MustGetLogger("go_kafka")

func main() {
	fmt.Println("vim-go")
	groupID := "group-1"
	topicList := "topic_1"
	config := cluster.NewConfig()
	config.Consumer.Return.Errors = true
	config.Group.Return.Notifications = true
	config.Consumer.Offsets.CommitInterval = 1 * time.Second
	config.Consumer.Offsets.Initial = sarama.OffsetNewest //初始从最新的offset开始

	c, err := cluster.NewConsumer(strings.Split("localhost:9092", ","), groupID, strings.Split(topicList, ","), config)
	if err != nil {
		logger.Errorf("Failed open consumer: %v", err)
		return
	}
	defer c.Close()
	go func() {
		for err := range c.Errors() {
			logger.Errorf("Error: %s\n", err.Error())
		}
	}()

	go func() {
		for note := range c.Notifications() {
			logger.Infof("Rebalanced: %+v\n", note)
		}
	}()

	for msg := range c.Messages() {
		fmt.Fprintf(os.Stdout, "%s/%d/%d\t%s\n", msg.Topic, msg.Partition, msg.Offset, msg.Value)
		c.MarkOffset(msg, "") //MarkOffset 并不是实时写入kafka，有可能在程序crash时丢掉未提交的offset
	}
}
